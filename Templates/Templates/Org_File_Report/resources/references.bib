
@online{AnalysingGoogleRankings,
  title = {Analysing {{Google}} Rankings through Search Engine Optimization Data | {{Emerald Insight}}},
  url = {https://www-emerald-com.ezproxy.uws.edu.au/insight/content/doi/10.1108/10662240710730470/full/html},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/4QLKZR2I/Analysing Google rankings through search engine op.pdf;/home/ryan/Zotero/storage/HD8R6IPN/html.html}
}

@article{aspertGraphstructuredDatasetWikipedia2019,
  title = {A {{Graph}}-Structured {{Dataset}} for {{Wikipedia Research}}},
  author = {Aspert, Nicolas and Miz, Volodymyr and Ricaud, Benjamin and Vandergheynst, Pierre},
  date = {2019-05-13},
  journaltitle = {Companion Proceedings of The 2019 World Wide Web Conference},
  pages = {1188--1193},
  doi = {10.1145/3308560.3316757},
  url = {http://arxiv.org/abs/1903.08597},
  urldate = {2020-10-03},
  abstract = {Wikipedia is a rich and invaluable source of information. Its central place on the Web makes it a particularly interesting object of study for scientists. Researchers from different domains used various complex datasets related to Wikipedia to study language, social behavior, knowledge organization, and network theory. While being a scientific treasure, the large size of the dataset hinders pre-processing and may be a challenging obstacle for potential new studies. This issue is particularly acute in scientific domains where researchers may not be technically and data processing savvy. On one hand, the size of Wikipedia dumps is large. It makes the parsing and extraction of relevant information cumbersome. On the other hand, the API is straightforward to use but restricted to a relatively small number of requests. The middle ground is at the mesoscopic scale when researchers need a subset of Wikipedia ranging from thousands to hundreds of thousands of pages but there exists no efficient solution at this scale. In this work, we propose an efficient data structure to make requests and access subnetworks of Wikipedia pages and categories. We provide convenient tools for accessing and filtering viewership statistics or "pagecounts" of Wikipedia web pages. The dataset organization leverages principles of graph databases that allows rapid and intuitive access to subgraphs of Wikipedia articles and categories. The dataset and deployment guidelines are available on the LTS2 website \textbackslash url\{https://lts2.epfl.ch/Datasets/Wikipedia/\}.},
  archivePrefix = {arXiv},
  eprint = {1903.08597},
  eprinttype = {arxiv},
  file = {/home/ryan/Zotero/storage/2VSRWHNA/aspertGraphstructuredDatasetWikipedia2019.pdf;/home/ryan/Zotero/storage/M6J82ZU5/1903.html},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Computer Science - Social and Information Networks}
}

@article{aspertGraphstructuredDatasetWikipedia2019a,
  title = {A {{Graph}}-Structured {{Dataset}} for {{Wikipedia Research}}},
  author = {Aspert, Nicolas and Miz, Volodymyr and Ricaud, Benjamin and Vandergheynst, Pierre},
  date = {2019-05-13},
  journaltitle = {Companion Proceedings of The 2019 World Wide Web Conference},
  pages = {1188--1193},
  doi = {10.1145/3308560.3316757},
  url = {http://arxiv.org/abs/1903.08597},
  urldate = {2020-10-03},
  abstract = {Wikipedia is a rich and invaluable source of information. Its central place on the Web makes it a particularly interesting object of study for scientists. Researchers from different domains used various complex datasets related to Wikipedia to study language, social behavior, knowledge organization, and network theory. While being a scientific treasure, the large size of the dataset hinders preprocessing and may be a challenging obstacle for potential new studies. This issue is particularly acute in scientific domains where researchers may not be technically and data processing savvy. On one hand, the size of Wikipedia dumps is large. It makes the parsing and extraction of relevant information cumbersome. On the other hand, the API is straightforward to use but restricted to a relatively small number of requests. The middle ground is at the mesoscopic scale, when researchers need a subset of Wikipedia ranging from thousands to hundreds of thousands of pages but there exists no efficient solution at this scale.},
  archivePrefix = {arXiv},
  eprint = {1903.08597},
  eprinttype = {arxiv},
  file = {/home/ryan/Zotero/storage/7FTXD3CP/Aspert et al. - 2019 - A Graph-structured Dataset for Wikipedia Research.pdf},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  langid = {english}
}

@article{berkhoutRankingNodesGeneral2018,
  title = {Ranking Nodes in General Networks: A {{Markov}} Multi-Chain Approach},
  shorttitle = {Ranking Nodes in General Networks},
  author = {Berkhout, Joost and Heidergott, Bernd F.},
  date = {2018-03-01},
  journaltitle = {Discrete Event Dyn Syst},
  volume = {28},
  pages = {3--33},
  issn = {1573-7594},
  doi = {10.1007/s10626-017-0248-7},
  url = {https://doi.org/10.1007/s10626-017-0248-7},
  urldate = {2020-08-18},
  abstract = {The basis of Google’s acclaimed PageRank is an artificial mixing of the Markov chain representing the connectivity structure of the network under study with a maximally connected network where every node is connected to every other node. The rate with which the original network is mixed with the strongly connected one is called damping factor. The choice of the damping factor can influence the ranking of the nodes. As we show in this paper, the ranks of transient nodes, i.e., nodes not belonging to a strongly connected component without outgoing links in the original network, tend to zero as the damping factor increases. In this paper we develop a new methodology for obtaining a meaningful ranking of nodes without having to resort to mixing the network with an artificial one. Our new ranking relies on an adjusted definition of the ergodic projector of the Markov chain representing the original network. We will show how the new ergodic projector leads to a more structural way of ranking (transient) nodes. Numerical examples are provided to illustrate the impact of this new ranking approach.},
  file = {/home/ryan/Zotero/storage/KBU5C4I9/Berkhout and Heidergott - 2018 - Ranking nodes in general networks a Markov multi-.pdf},
  langid = {english},
  number = {1}
}

@article{berkhoutRankingNodesGeneral2018a,
  title = {Ranking Nodes in General Networks: A {{Markov}} Multi-Chain Approach},
  shorttitle = {Ranking Nodes in General Networks},
  author = {Berkhout, Joost and Heidergott, Bernd F.},
  date = {2018-03-01},
  journaltitle = {Discrete Event Dyn Syst},
  volume = {28},
  pages = {3--33},
  issn = {1573-7594},
  doi = {10.1007/s10626-017-0248-7},
  url = {https://doi.org/10.1007/s10626-017-0248-7},
  urldate = {2020-08-19},
  abstract = {The basis of Google’s acclaimed PageRank is an artificial mixing of the Markov chain representing the connectivity structure of the network under study with a maximally connected network where every node is connected to every other node. The rate with which the original network is mixed with the strongly connected one is called damping factor. The choice of the damping factor can influence the ranking of the nodes. As we show in this paper, the ranks of transient nodes, i.e., nodes not belonging to a strongly connected component without outgoing links in the original network, tend to zero as the damping factor increases. In this paper we develop a new methodology for obtaining a meaningful ranking of nodes without having to resort to mixing the network with an artificial one. Our new ranking relies on an adjusted definition of the ergodic projector of the Markov chain representing the original network. We will show how the new ergodic projector leads to a more structural way of ranking (transient) nodes. Numerical examples are provided to illustrate the impact of this new ranking approach.},
  file = {/home/ryan/Zotero/storage/DMEFX9X8/Berkhout and Heidergott - 2018 - Ranking nodes in general networks a Markov multi-.pdf},
  keywords = {markov,pagerank},
  langid = {english},
  note = {The choice of damping factor of Googles page rank might have a large impact on the values given to vertices.
\par
This suggests an approach that uses structural network dynatims to provide an appropriate score distribution.
\par
The method implemented is not something I have come yet to understand, but it could be very interesting to see:
\par
- how it relates to the power walk method\\
- whether or not it could offer insightts into the convergence and stability of the power walk method\\
- Whether or not the method would be compatible with negatively weighted edges.},
  number = {1}
}

@online{berkleyuniversityBusinessLibraryUC,
  title = {Business {{Library}} | {{UC Berkeley Library}}},
  author = {{Berkley University}},
  url = {https://www.lib.berkeley.edu/libraries/business-library},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/2PBVCX93/business-library.html}
}

@article{bianchiniPageRank2005,
  title = {Inside {{PageRank}}},
  author = {Bianchini, Monica and Gori, Marco and Scarselli, Franco},
  date = {2005-02-01},
  journaltitle = {ACM Trans. Inter. Tech.},
  volume = {5},
  pages = {92--128},
  issn = {15335399},
  doi = {10.1145/1052934.1052938},
  url = {http://portal.acm.org/citation.cfm?doid=1052934.1052938},
  urldate = {2020-08-18},
  file = {/home/ryan/Zotero/storage/WWSXB8L2/Bianchini et al. - 2005 - Inside PageRank.pdf},
  langid = {english},
  note = {This is a discussion on the stability, complexity and critical role of parameters involved in the computation.},
  number = {1}
}

@inproceedings{boldiPageRankFunctionDamping2005,
  title = {{{PageRank}} as a Function of the Damping Factor},
  booktitle = {Proceedings of the 14th International Conference on {{World Wide Web}}},
  author = {Boldi, Paolo and Santini, Massimo and Vigna, Sebastiano},
  date = {2005-05-10},
  pages = {557--566},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/1060745.1060827},
  url = {http://doi.org/10.1145/1060745.1060827},
  urldate = {2020-08-19},
  abstract = {PageRank is defined as the stationary state of a Markov chain. The chain is obtained by perturbing the transition matrix induced by a web graph with a damping factor α that spreads uniformly part of the rank. The choice of α is eminently empirical, and in most cases the original suggestion α = 0.85 by Brin and Page is still used. Recently, however, the behaviour of PageRank with respect to changes in α was discovered to be useful in link-spam detection[21]. Moreover, an analytical justification of the value chosen for α is still missing. In this paper, we give the first mathematical analysis of PageRank when α changes. In particular, we show that, contrarily to popular belief, for real-world graphs values of α close to 1 do not give a more meaningful ranking. Then, we give closed-form formulae for PageRank derivatives of any order, and an extension of the Power Method that approximates them with convergence O (tk αt) for the k-th derivative. Finally, we show a tight connection between iterated computation and analytical behaviour by proving that the k-th iteration of the Power Method gives exactly the PageRank value obtained using a Maclaurin polynomial of degree k. The latter result paves the way towards the application of analytical methods to the study of PageRank.},
  file = {/home/ryan/Zotero/storage/ZQQJJBXR/Boldi et al. - 2005 - PageRank as a function of the damping factor.pdf},
  isbn = {978-1-59593-046-0},
  keywords = {approximation,PageRank,Web graph},
  series = {{{WWW}} '05}
}

@incollection{bottDatabaseSearching2012,
  title = {Database {{Searching}}},
  booktitle = {Nemes and {{Coss}}' Effective Legal Research},
  author = {Bott, Bruce and Talbot-Stokes, Ruth and Nemes, Irene},
  date = {2012},
  edition = {5th ed},
  publisher = {{LexisNexis Butterworths}},
  location = {{Chatswood, N.S.W}},
  annotation = {OCLC: 775657696},
  isbn = {978-0-409-33063-2},
  keywords = {Australia,Legal research}
}

@book{bottNemesCossEffective2012,
  title = {Nemes and {{Coss}}' Effective Legal Research},
  author = {Bott, Bruce and Talbot-Stokes, Ruth and Nemes, Irene},
  date = {2012},
  edition = {5th ed},
  publisher = {{LexisNexis Butterworths}},
  location = {{Chatswood, N.S.W}},
  annotation = {OCLC: 775657696},
  isbn = {978-0-409-33063-2},
  keywords = {Australia,Legal research},
  note = {Previous ed.: 2010},
  pagetotal = {370}
}

@article{brinkmeierPageRankRevisited2006a,
  title = {{{PageRank Revisited}}},
  author = {Brinkmeier, Michael},
  date = {2006-08},
  journaltitle = {ACM Transactions on Internet Technology},
  volume = {6},
  pages = {282--301},
  publisher = {{Association for Computing Machinery}},
  issn = {15335399},
  doi = {10.1145/1151087.1151090},
  url = {http://ezproxy.uws.edu.au/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=iih&AN=22173011&site=ehost-live&scope=site},
  urldate = {2020-08-19},
  abstract = {PageRank, one part of the search engine Google, is one of the most prominent link-based rankings of documents in the World Wide Web. Usually it is described as a Markov chain modeling a specific random surfer. In this article, an alternative representation as a power series is given. Nonetheless, it is possible to interpret the values as probabilities in a random surfer setting, differing from the usual one. Using the new description we restate and extend some results concerning the convergence of the standard iteration used for PageRank. Furthermore we take a closer look at sinks and sources, leading to some suggestions for faster implementations.},
  file = {/home/ryan/Zotero/storage/V2WCGXRV/Brinkmeier - 2006 - PageRank Revisited.pdf},
  keywords = {Algorithms,Dynamical update,Google Inc.,Internet searching,link-analysis,Markov chain,Markov processes,Pagerank,personalization,random surfer,ranking algorithm,Stochastic processes,Theory,Web graph,Web page scoring,Web search,World Wide Web},
  number = {3}
}

@article{bryan250000002006,
  title = {The \$25,000,000,000 {{Eigenvector}}: {{The Linear Algebra}} behind {{Google}}},
  shorttitle = {The \$25,000,000,000 {{Eigenvector}}},
  author = {Bryan, Kurt and Leise, Tanya},
  date = {2006},
  journaltitle = {SIAM Review},
  volume = {48},
  pages = {569--581},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  abstract = {Google's success derives in large part from its PageRank algorithm, which ranks the importance of web pages according to an eigenvector of a weighted link matrix. Analysis of the PageRank formula provides a wonderful applied topic for a linear algebra course. Instructors may assign this article as a project to more advanced students or spend one or two lectures presenting the material with assigned homework from the exercises. This material also complements the discussion of Markov chains in matrix algebra. Maple and Mathematica files supporting this material can be found at www.rose-hulman.edu/∼bryan.},
  eprint = {20453840},
  eprinttype = {jstor},
  number = {3}
}

@inproceedings{bulucParallelSparseMatrixvector2009,
  title = {Parallel Sparse Matrix-Vector and Matrix-Transpose-Vector Multiplication Using Compressed Sparse Blocks},
  booktitle = {Proceedings of the Twenty-First Annual Symposium on {{Parallelism}} in Algorithms and Architectures - {{SPAA}} '09},
  author = {Buluç, Aydin and Fineman, Jeremy T. and Frigo, Matteo and Gilbert, John R. and Leiserson, Charles E.},
  date = {2009},
  pages = {233},
  publisher = {{ACM Press}},
  location = {{Calgary, AB, Canada}},
  doi = {10.1145/1583991.1584053},
  url = {http://portal.acm.org/citation.cfm?doid=1583991.1584053},
  urldate = {2020-08-07},
  abstract = {This paper introduces a storage format for sparse matrices, called compressed sparse blocks (CSB), which allows both Ax and ATx to be computed efficiently in parallel, where A is an n × n sparse r(mictrahittmriicxsaulw-spietahtΘhn(nnleznn≥zg)tnwh)on, rokyniz(eseledroriinsaglanraudnpxnaiirnsaglaltedilmeisnems)eaonnf-dvΘeΘc((tn√onr.nz /lOg√unrn)alsglpgnao)n-, which is amply high for virtually any large matrix. The storage requirement for CSB is esssentially the same as that for the morestandard compressed-sparse-rows (CSR) format, for which computing Ax in parallel is easy but ATx is difficult. Benchmark results indicate that on one processor, the CSB algorithms for Ax and ATx run just as fast as the CSR algorithm for Ax, but the CSB algorithms also scale up linearly with processors until limited by offchip memory bandwidth.},
  eventtitle = {The Twenty-First Annual Symposium},
  file = {/home/ryan/Zotero/storage/XIQASNAW/Buluç et al. - 2009 - Parallel sparse matrix-vector and matrix-transpose.pdf},
  isbn = {978-1-60558-606-9},
  langid = {english}
}

@inreference{CategoryMathematics2019,
  title = {Category:{{Mathematics}}},
  shorttitle = {Category},
  booktitle = {Wikipedia},
  date = {2019-12-04T10:49:52Z},
  url = {https://en.wikipedia.org/w/index.php?title=Category:Mathematics&oldid=929215996},
  urldate = {2020-08-19},
  abstract = {Mathematics (colloquially, maths, or math), is the body of knowledge centered on concepts such as quantity, structure, space, and change, and also the academic discipline that studies them.},
  annotation = {Page Version ID: 929215996},
  file = {/home/ryan/Zotero/storage/9BLCNCBX/index.html},
  langid = {english}
}

@online{consingLibGuidesResearchGuides,
  title = {{{LibGuides}}: {{Research Guides}}: {{Home}}},
  shorttitle = {{{LibGuides}}},
  author = {Consing, Augusto},
  url = {https://simmons.libguides.com/c.php?g=938010&p=6760146},
  urldate = {2020-08-19},
  abstract = {LibGuides: Research Guides: Home},
  file = {/home/ryan/Zotero/storage/5PPKAVVZ/home.html},
  langid = {english}
}

@article{damesSearchingVsBrowsing2019a,
  title = {Searching vs. {{Browsing}}—{{The Influence}} of {{Consumers}}’ {{Goal Directedness}} on {{Website Evaluations}}},
  author = {Dames, Hannah and Hirschfeld, Gerrit and Sackmann, Timo and Thielsch, Meinald T.},
  date = {2019-01-01},
  journaltitle = {Interact Comput},
  volume = {31},
  pages = {95--112},
  publisher = {{Oxford Academic}},
  issn = {0953-5438},
  doi = {10.1093/iwc/iwz006},
  url = {http://academic.oup.com/iwc/article/31/1/95/5477831},
  urldate = {2020-08-18},
  abstract = {AbstractUsers access the Internet not only to pursue specific goals (e.g. searching for information), but also to browse through content in a more exploratory f},
  langid = {english},
  number = {1}
}

@article{dekerchoveMaximizingPageRankOutlinks2008,
  title = {Maximizing {{PageRank}} via Outlinks},
  author = {de Kerchove, Cristobald and Ninove, Laure and van Dooren, Paul},
  date = {2008-09},
  journaltitle = {Linear Algebra and its Applications},
  volume = {429},
  pages = {1254--1276},
  issn = {00243795},
  doi = {10.1016/j.laa.2008.01.023},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0024379508000529},
  urldate = {2020-08-21},
  file = {/home/ryan/Zotero/storage/GVKBG8IS/dekerchoveMaximizingPageRankOutlinks2008.pdf},
  langid = {english},
  number = {5-6},
  options = {useprefix=true}
}

@article{dingCentralityRankingMultiplex2018,
  title = {Centrality Ranking in Multiplex Networks Using Topologically Biased Random Walks},
  author = {Ding, Cangfeng and Li, Kan},
  date = {2018-10-27},
  journaltitle = {Neurocomputing},
  volume = {312},
  pages = {263--275},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2018.05.109},
  url = {http://www.sciencedirect.com/science/article/pii/S0925231218307069},
  urldate = {2020-08-19},
  abstract = {Characterizing the statistically significant centrality of nodes is one of the main goals of multiplex networks. However, current centrality measures for node rankings focus only on either random walks or on the topological structure of the network. A pressing challenge is how to measure centrality of nodes in multiplex networks, depending both on network topology and on the biased types of random walks, such as the biased walks dealing with the properties of each node separately at each layer, or the biased walks considering instead one or even more intrinsically multiplex properties of the arrival node. In the paper, considering these two aspects, we propose a mathematical framework based on topologically biased random walk, called topologically biased multiplex PageRank, which allows to calculate centrality and accordingly rank nodes in multiplex networks. In particular, depending on the nature of biases and the interaction of nodes between different layers, we distinguish additive, multiplicative and combined cases of topologically biased multiplex PageRank. Each case by tuning the bias parameters reflects how the centrality ranking of a node in one layer affects the ranking its replica can gain in the other layers, and captures the extent to which the walkers preferentially visit hubs or poorly connected nodes. Experiments on two real-world multiplex networks show that the topologically biased multiplex PageRank outperforms both its corresponding unbiased case and the current ranking methods, and it can efficiently capture the significantly top-ranked nodes in multiplex networks by means of a proper tuning of the biases in the walks.},
  file = {/home/ryan/Zotero/storage/KQ6T8QSS/Ding and Li - 2018 - Centrality ranking in multiplex networks using top.pdf},
  keywords = {Biased random walks,Centrality ranking,Multiplex networks,PageRank},
  langid = {english}
}

@article{dunsmoreQualitativeStudyWebMounted2002,
  title = {A {{Qualitative Study}} of {{Web}}-{{Mounted Pathfinders Created}} by {{Academic Business Libraries}}},
  author = {Dunsmore, Carla},
  date = {2002-09-01},
  journaltitle = {Libri},
  volume = {52},
  pages = {137--156},
  publisher = {{De Gruyter Saur}},
  doi = {10.1515/LIBR.2002.137},
  url = {https://www.degruyter.com/view/journals/libr/52/3/article-p137.xml},
  urldate = {2020-08-18},
  abstract = {{$<$}section class="abstract"{$><$}p{$>$}The nature of academic business pathfinders or subject guides mounted on the Internet was examined by qualitative content analysis. Specifically, the research sought to understand the concept, purposes and principles of pathfinders; the terminology representing pathfinders; the navigational pathway through the library Website to the pathfinders; and their common contents. Ten Canadian and ten American academic library Websites were sampled for pathfinders on three business topics: company, industry and marketing. Findings showed that the traditional term ‘pathfinder’ was not used on these academic Websites; instead ‘subject guides’ or ‘research guides’ were the most popular synonyms. The content analysis identified that subject guides have two basic functions, which are to facilitate access and to provide a search strategy. Four principles were found for creating Webmounted, subject guides: accessibility, consistency, selectivity, and transparency. The research also found that subject guides are important library finding tools as evidenced by the time and effort devoted to their creation, and their placement on valuable library homepage screen space.{$<$}/p{$><$}/section{$>$}},
  file = {/home/ryan/Zotero/storage/MT7SVAXC/article-p137.html},
  langid = {english},
  number = {3}
}

@software{Epfllts2Sparkwiki2020,
  title = {Epfl-Lts2/Sparkwiki},
  date = {2020-07-06T07:42:33Z},
  origdate = {2018-09-06T12:41:47Z},
  url = {https://github.com/epfl-lts2/sparkwiki},
  urldate = {2020-10-03},
  abstract = {Contribute to epfl-lts2/sparkwiki development by creating an account on GitHub.},
  organization = {{EPFL LTS2}}
}

@article{farahatAuthorityRankingsHITS2006,
  title = {Authority {{Rankings}} from {{HITS}}, {{PageRank}}, and {{SALSA}}: {{Existence}}, {{Uniqueness}}, and {{Effect}} of {{Initialization}}},
  shorttitle = {Authority {{Rankings}} from {{HITS}}, {{PageRank}}, and {{SALSA}}},
  author = {Farahat, Ayman and LoFaro, Thomas and Miller, Joel C. and Rae, Gregory and Ward, Lesley A.},
  date = {2006},
  journaltitle = {SIAM Journal on Scientific Computing; Philadelphia},
  volume = {27},
  pages = {21},
  publisher = {{Society for Industrial and Applied Mathematics}},
  location = {{Philadelphia, United States, Philadelphia}},
  issn = {10648275},
  doi = {http://dx.doi.org.ezproxy.uws.edu.au/10.1137/S1064827502412875},
  url = {http://search.proquest.com/docview/921166362/abstract/9367723222824064PQ/1},
  urldate = {2020-08-19},
  abstract = {Algorithms such as Kleinberg's HITS algorithm, the PageRank algorithm of Brin and Page, and the SALSA algorithm of Lempel and Moran use the link structure of a network of web pages to assign weights to each page in the network. The weights can then be used to rank the pages as authoritative sources. These algorithms share a common underpinning; they find a dominant eigenvector of a nonnegative matrix that describes the link structure of the given network and use the entries of this eigenvector as the page weights. We use this commonality to give a unified treatment, proving the existence of the required eigenvector for the PageRank, HITS, and SALSA algorithms, the uniqueness of the PageRank eigenvector, and the convergence of the algorithms to these eigenvectors. However, we show that the HITS and SALSA eigenvectors need not be unique. We examine how the initialization of the algorithms affects the final weightings produced. We give examples of networks that lead the HITS and SALSA algorithms to returnnonunique or nonintuitive rankings. We characterize all such networks in terms of the connectivity of the related HITS authority graph. We propose a modification, Exponentiated Input to HITS, to the adjacency matrix input to the HITS algorithm. We prove that Exponentiated Input to HITS returns a unique ranking, provided that the network is weakly connected. Our examples also show that SALSA can give inconsistent hub and authority weights, due to nonuniqueness. We also mention a small modification to the SALSA initialization which makes the hub and authority weights consistent.},
  file = {/home/ryan/Zotero/storage/3DR5ESLR/Farahat et al. - 2006 - Authority Rankings from HITS, PageRank, and SALSA.pdf},
  keywords = {Mathematics},
  langid = {english},
  number = {4},
  pagetotal = {21}
}

@article{frahmPageRankIntegers2012,
  title = {{{PageRank}} of Integers},
  author = {Frahm, K M and Chepelianskii, A D and Shepelyansky, D L},
  date = {2012-10-12},
  journaltitle = {J. Phys. A: Math. Theor.},
  volume = {45},
  pages = {405101},
  issn = {1751-8113, 1751-8121},
  doi = {10.1088/1751-8113/45/40/405101},
  url = {https://iopscience.iop.org/article/10.1088/1751-8113/45/40/405101},
  urldate = {2020-08-21},
  file = {/home/ryan/Zotero/storage/5MDB6CKC/PageRank of integers - IOPscience.pdf;/home/ryan/Zotero/storage/UQVYW3I5/frahmPageRankIntegers2012.pdf;/home/ryan/Zotero/storage/Z8AGYCIR/405101.html},
  number = {40}
}

@article{fuDampingFactorGoogle2006,
  title = {Damping Factor in {{Google}} Page Ranking},
  author = {Fu, Hwai-Hui and Lin, Dennis K. J. and Tsai, Hsien-Tang},
  date = {2006},
  journaltitle = {Applied Stochastic Models in Business and Industry},
  volume = {22},
  pages = {431--444},
  issn = {1526-4025},
  doi = {10.1002/asmb.656},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/asmb.656},
  urldate = {2020-08-19},
  abstract = {Google, the largest search engine worldwide, adopts PageRank technology to determine the rank of website listings. This paper describes how damping factor is a critical factor in changing a website's ranking in traditional Google PageRank technology. A modified algorithm based on input–output ratio concept is proposed to substitute for the damping factor. Besides there is no need to choose an optimal damping factor value, the modified algorithm has an equivalent effect on computation as the traditional Google's PageRank algorithm. Copyright © 2006 John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asmb.656},
  file = {/home/ryan/Zotero/storage/A8K6MK8M/Fu et al. - 2006 - Damping factor in Google page ranking.pdf},
  keywords = {input–output ratio,search engine},
  langid = {english},
  number = {5-6}
}

@online{gaborcsardiIgraphManualPages2019,
  title = {Igraph {{R}} Manual Pages},
  author = {{Gabor Csardi} and {Tamas Nepusz} and {Szabolcs Horvat} and {Vincent Traag}},
  date = {2019-05-09},
  url = {https://igraph.org/r/doc/as_adjacency_matrix.html},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/U7Z3MDQU/as_adjacency_matrix.html}
}

@online{garritanoWikipediaArticleNetworks2019,
  title = {Wikipedia {{Article Networks}}},
  author = {Garritano, Andrea},
  date = {2019-12},
  journaltitle = {Kaggle},
  url = {https://kaggle.com/andreagarritano/wikipedia-article-networks},
  urldate = {2020-10-03},
  abstract = {Kaggle is the world’s largest data science community with powerful tools and resources to help you achieve your data science goals.},
  file = {/home/ryan/Zotero/storage/LWJI5SB3/wikipedia-article-networks.html},
  langid = {english}
}

@article{gleichMODELSALGORITHMSPAGERANK,
  title = {{{MODELS AND ALGORITHMS FOR PAGERANK SENSITIVIT Y}}},
  author = {Gleich, David Francis},
  pages = {198},
  file = {/home/ryan/Zotero/storage/3SSUAKWZ/Gleich - MODELS AND ALGORITHMS FOR PAGERANK SENSITIVIT Y.pdf},
  langid = {english}
}

@online{GoogleBooksNgram,
  title = {Google {{Books Ngram Viewer}}},
  url = {https://books.google.com/ngrams/graph?content=Zettelkasten&corpus=26&year_end=2019&year_start=1800&smoothing=3&direct_url=t1%3B%2CZettelkasten%3B%2Cc0#t1%3B%2CZettelkasten%3B%2Cc0},
  urldate = {2020-08-19},
  abstract = {Google Books Ngram Viewer},
  file = {/home/ryan/Zotero/storage/MJJQWHHD/graph.html},
  langid = {english}
}

@online{haarkoetterAllesWesentlicheFindet,
  title = {"Alles Wesentliche findet sich im Zettelkasten"},
  author = {Haarkötter, Hektor},
  journaltitle = {heise online},
  url = {https://www.heise.de/tp/features/Alles-Wesentliche-findet-sich-im-Zettelkasten-3398418.html},
  urldate = {2020-08-19},
  abstract = {Zur Geschichte einer ausgestorbenen Medientechnik},
  file = {/home/ryan/Zotero/storage/6URQFZ69/Alles-Wesentliche-findet-sich-im-Zettelkasten-3398418.html},
  langid = {german}
}

@article{harbesonTeachingReferenceBibliography1972,
  title = {Teaching {{Reference}} and {{Bibliography}}: {{The Pathfinder Approach}}},
  shorttitle = {Teaching {{Reference}} and {{Bibliography}}},
  author = {Harbeson, Eloise L.},
  date = {1972},
  journaltitle = {Journal of Education for Librarianship},
  volume = {13},
  pages = {111},
  issn = {00220604},
  doi = {10.2307/40322211},
  eprint = {10.2307/40322211},
  eprinttype = {jstor},
  file = {/home/ryan/Zotero/storage/LM2R57VI/40322211.html},
  langid = {english},
  number = {2}
}

@online{harvarduniversityResearchGuides,
  title = {Research {{Guides}}},
  author = {{Harvard University}},
  url = {https://guides.library.harvard.edu/},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/QAZ7AD7N/guides.library.harvard.edu.html},
  langid = {english}
}

@article{haveliwalaSecondEigenvalueGoogle2003,
  title = {The {{Second Eigenvalue}} of the {{Google Matrix}}},
  author = {Haveliwala, Taher and Kamvar, Sepander},
  date = {2003},
  journaltitle = {Stanford Technical Report},
  url = {https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwi5x7iBhqnrAhVTfisKHQp8CrYQFjAAegQIBRAB&url=https%3A%2F%2Fnlp.stanford.edu%2Fpubs%2Fsecondeigenvalue.pdf&usg=AOvVaw3Em9lm2qOuWEN23PXhUS8J},
  abstract = {We determine analytically the modulus of the second eigenvalue forthe web hyperlink matrix used by Google for computing PageRank. Specifically,we prove the following statement:“For any matrixA= [cP+ (1−c)E]T, wherePis ann×nrow-stochasticmatrix,Eis a nonnegativen×nrank-one row-stochastic matrix, and0≤c≤1,the second eigenvalue ofAhas modulus|λ2|≤c. Furthermore, ifPhas at leasttwo irreducible closed subsets, the second eigenvalueλ2=c.”This statement has implications for the convergence rate ofthe standard PageR-ank algorithm as the web scales, for the stability of PageRank to perturbations tothe link structure of the web, for the detection of Google spammers, and for thedesign of algorithms to speed up PageRan},
  file = {/home/ryan/Zotero/storage/BEMZEB8M/Haveliwala and Kamvar - 2003 - The Second Eigenvalue of the Google Matrix.pdf}
}

@online{HelpCategoriesMediaWiki,
  title = {Help:{{Categories}} - {{MediaWiki}}},
  url = {https://www.mediawiki.org/wiki/Help:Categories},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/YGW8PA58/HelpCategories.html}
}

@article{ingawaleNetworkAnalysisUser2013a,
  title = {Network Analysis of User Generated Content Quality in {{Wikipedia}}},
  author = {Ingawale, Myshkin and Dutta, Amitava and Roy, Rahul and Seetharaman, Priya},
  date = {2013-01-01},
  journaltitle = {Online Information Review},
  volume = {37},
  pages = {602--619},
  publisher = {{Emerald Group Publishing Limited}},
  issn = {1468-4527},
  doi = {10.1108/OIR-03-2011-0182},
  url = {https://doi.org/10.1108/OIR-03-2011-0182},
  urldate = {2020-08-17},
  abstract = {Purpose – Social media platforms allow near‐unfettered creation and exchange of user generated content (UGC). Drawing from network science, the purpose of this paper is to examine whether high and low quality UGC differ in their connectivity structures in Wikipedia (which consists of interconnected user generated articles). Design/methodology/approach – Using Featured Articles as a proxy for high quality, a network analysis was undertaken of the revision history of six different language Wikipedias, to offer a network‐centric explanation for the emergence of quality in UGC. Findings – The network structure of interactions between articles and contributors plays an important role in the emergence of quality. Specifically the analysis reveals that high‐quality articles cluster in hubs that span structural holes. Research limitations/implications – The analysis does not capture the strength of interactions between articles and contributors. The implication of this limitation is that quality is viewed as a binary variable. Extensions to this research will relate strength of interactions to different levels of quality in UGC. Practical implications – The findings help harness the “wisdom of the crowds” effectively. Organisations should nurture users and articles at the structural hubs from an early stage. This can be done through appropriate design of collaborative knowledge systems and development of organisational policies to empower hubs. Originality/value – The network centric perspective on quality in UGC and the use of a dynamic modelling tool are novel. The paper is of value to researchers in the area of social computing and to practitioners implementing and maintaining such platforms in organisations.},
  file = {/home/ryan/Zotero/storage/IZ5SPT9A/Ingawale et al. - 2013 - Network analysis of user generated content quality.pdf},
  keywords = {Hubs,Network analysis,Quality,Social computing,Structural holes,Web sites; Wikis; Social media; Wikipedia},
  note = {Is there a relationship between content quality and the structure of connections? Can high quality Wikipedia pages be used as a benchmark for the structure of connections.
\par
The network structure of interactions between articles plays an important role in the emergence of quality.
\par
High quality articles clusture in hubs.},
  number = {4}
}

@article{kamvarAdaptiveMethodsComputation2004,
  title = {Adaptive Methods for the Computation of {{PageRank}}},
  author = {Kamvar, Sepandar and Haveliwala, Taher and Golub, Gene},
  date = {2004-07-15},
  journaltitle = {Linear Algebra and its Applications},
  volume = {386},
  pages = {51--65},
  issn = {0024-3795},
  doi = {10.1016/j.laa.2003.12.008},
  url = {http://www.sciencedirect.com/science/article/pii/S0024379504000023},
  urldate = {2020-07-31},
  abstract = {We observe that the convergence patterns of pages in the PageRank algorithm have a nonuniform distribution. Specifically, many pages converge to their true PageRank quickly, while relatively few pages take a much longer time to converge. Furthermore, we observe that these slow-converging pages are generally those pages with high PageRank. We use this observation to devise a simple algorithm to speed up the computation of PageRank, in which the PageRank of pages that have converged are not recomputed at each iteration after convergence. This algorithm, which we call Adaptive PageRank, speeds up the computation of PageRank by nearly 30\%.},
  file = {/home/ryan/Zotero/storage/Y6BCQZP9/Kamvar et al. - 2004 - Adaptive methods for the computation of PageRank.pdf},
  keywords = {Eigenvalue problem,PageRank,Web matrix},
  langid = {english},
  note = {Given a graph, how can we optimise the discoverability of a node by introducing a couple of edges. A node is considered as discoverable if it:
\par
1. Has a high page rank value\\
2. The number of steps to reach that vertex from another vertex is low.},
  series = {Special {{Issue}} on the {{Conference}} on the {{Numerical Solution}} of {{Markov Chains}} 2003}
}

@article{kamvarAdaptiveMethodsComputation2004a,
  title = {Adaptive Methods for the Computation of {{PageRank}}},
  author = {Kamvar, Sepandar and Haveliwala, Taher and Golub, Gene},
  date = {2004-07-15},
  journaltitle = {Linear Algebra and its Applications},
  volume = {386},
  pages = {51--65},
  issn = {0024-3795},
  doi = {10.1016/j.laa.2003.12.008},
  url = {http://www.sciencedirect.com/science/article/pii/S0024379504000023},
  urldate = {2020-08-19},
  abstract = {We observe that the convergence patterns of pages in the PageRank algorithm have a nonuniform distribution. Specifically, many pages converge to their true PageRank quickly, while relatively few pages take a much longer time to converge. Furthermore, we observe that these slow-converging pages are generally those pages with high PageRank. We use this observation to devise a simple algorithm to speed up the computation of PageRank, in which the PageRank of pages that have converged are not recomputed at each iteration after convergence. This algorithm, which we call Adaptive PageRank, speeds up the computation of PageRank by nearly 30\%.},
  file = {/home/ryan/Zotero/storage/94UY4P2E/Kamvar et al. - 2004 - Adaptive methods for the computation of PageRank.pdf},
  keywords = {Eigenvalue problem,PageRank,Web matrix},
  langid = {english},
  series = {Special {{Issue}} on the {{Conference}} on the {{Numerical Solution}} of {{Markov Chains}} 2003}
}

@article{kamvarAdaptiveMethodsComputation2004b,
  title = {Adaptive Methods for the Computation of {{PageRank}}},
  author = {Kamvar, Sepandar and Haveliwala, Taher and Golub, Gene},
  date = {2004-07-15},
  journaltitle = {Linear Algebra and its Applications},
  volume = {386},
  pages = {51--65},
  issn = {0024-3795},
  doi = {10.1016/j.laa.2003.12.008},
  url = {http://www.sciencedirect.com/science/article/pii/S0024379504000023},
  urldate = {2020-08-19},
  abstract = {We observe that the convergence patterns of pages in the PageRank algorithm have a nonuniform distribution. Specifically, many pages converge to their true PageRank quickly, while relatively few pages take a much longer time to converge. Furthermore, we observe that these slow-converging pages are generally those pages with high PageRank. We use this observation to devise a simple algorithm to speed up the computation of PageRank, in which the PageRank of pages that have converged are not recomputed at each iteration after convergence. This algorithm, which we call Adaptive PageRank, speeds up the computation of PageRank by nearly 30\%.},
  file = {/home/ryan/Zotero/storage/V36BVDEV/Kamvar et al. - 2004 - Adaptive methods for the computation of PageRank.pdf},
  keywords = {Eigenvalue problem,PageRank,Web matrix},
  langid = {english},
  series = {Special {{Issue}} on the {{Conference}} on the {{Numerical Solution}} of {{Markov Chains}} 2003}
}

@article{kapounReThinkingLibraryPathfinder1995,
  title = {Re-{{Thinking}} the {{Library Pathfinder}}},
  author = {Kapoun, Jim M.},
  date = {1995-04-21},
  journaltitle = {College \& Undergraduate Libraries},
  volume = {2},
  pages = {93--105},
  issn = {1069-1316, 1545-2530},
  doi = {10.1300/J106v02n01_10},
  url = {http://www.tandfonline.com/doi/abs/10.1300/J106v02n01_10},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/MN9E2VKT/Kapoun - 1995 - Re-Thinking the Library Pathfinder.pdf},
  langid = {english},
  number = {1}
}

@article{koppelMeasuringDirectIndirect2014,
  title = {Measuring Direct and Indirect Authorial Influence in Historical Corpora},
  author = {Koppel, Moshe and Schweitzer, Nadav},
  date = {2014},
  journaltitle = {Journal of the Association for Information Science and Technology},
  volume = {65},
  pages = {2138--2144},
  issn = {2330-1643},
  doi = {10.1002/asi.23118},
  url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.23118},
  urldate = {2020-08-21},
  abstract = {We show how automatically extracted citations in historical corpora can be used to measure the direct and indirect influence of authors on each other. These measures can in turn be used to determine an author's overall prominence in the corpus and to identify distinct schools of thought. We apply our methods to two major historical corpora. Using scholarly consensus as a gold standard, we demonstrate empirically the superiority of indirect influence over direct influence as a basis for various measures of authorial impact.},
  annotation = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.23118},
  file = {/home/ryan/Zotero/storage/5FDG7RET/koppelMeasuringDirectIndirect2014.pdf;/home/ryan/Zotero/storage/YQ9JQYGF/asi.html},
  keywords = {knowledge},
  langid = {english},
  number = {10}
}

@article{langvilleReorderingPageRankProblem2006,
  title = {A {{Reordering}} for the {{PageRank Problem}}},
  author = {Langville, Amy N. and Meyer, Carl D.},
  date = {2006},
  journaltitle = {SIAM Journal on Scientific Computing; Philadelphia},
  volume = {27},
  pages = {9},
  publisher = {{Society for Industrial and Applied Mathematics}},
  location = {{Philadelphia, United States, Philadelphia}},
  issn = {10648275},
  doi = {http://dx.doi.org.ezproxy.uws.edu.au/10.1137/040607551},
  url = {http://search.proquest.com/docview/921138313/abstract/24AFC1417CF6412BPQ/1},
  urldate = {2020-08-19},
  abstract = {We describe a reordering particularly suited to the PageRank problem, which reduces the computation of the PageRank vector to that of solving a much smaller system and then using forward substitution to get the full solution vector. We compare the theoretical rates of convergence of the original PageRank algorithm to that of the new reordered PageRank algorithm, showing that the new algorithm can do no worse than the original algorithm. We present results of an experimental comparison on five datasets, which demonstrate that the reordered PageRank algorithm can provide a speedup of as much as a factor of 6. We also note potential additional benefits that result from the proposed reordering.},
  file = {/home/ryan/Zotero/storage/I5R5A6YY/Langville and Meyer - 2006 - A Reordering for the PageRank Problem.pdf},
  keywords = {Mathematics},
  langid = {english},
  number = {6},
  pagetotal = {9}
}

@article{langvilleSurveyEigenvectorMethods2005,
  title = {A {{Survey}} of {{Eigenvector Methods}} for {{Web Information Retrieval}}},
  author = {Langville, Amy N. and Meyer, Carl D.},
  date = {2005},
  journaltitle = {SIAM Review},
  volume = {47},
  pages = {135--161},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  abstract = {Web information retrieval is significantly more challenging than traditional well-controlled, small document collection information retrieval. One main difference between traditional information retrieval and Web information retrieval is the Web's hyperlink structure. This structure has been exploited by several of today's leading Web search engines, particularly Google and Teoma. In this survey paper, we focus on Web information retrieval methods that use eigenvector computations, presenting the three popular methods of HITS, PageRank, and SALSA.},
  eprint = {20453606},
  eprinttype = {jstor},
  file = {/home/ryan/Zotero/storage/JS8CDS99/Langville and Meyer - 2005 - A Survey of Eigenvector Methods for Web Informatio.pdf;/home/ryan/Zotero/storage/3Z9TAP2J/Langville and Meyer - 2005 - A Survey of Eigenvector Methods for Web Informatio.pdf;/home/ryan/Zotero/storage/M69WPZUP/Langville and Meyer - 2005 - A Survey of Eigenvector Methods for Web Informatio.pdf},
  number = {1}
}

@article{larrypageAnatomyLargescaleHypertextual1998,
  title = {The Anatomy of a Large-Scale Hypertextual {{Web}} Search Engine},
  author = {{Larry Page} and {Sergey Brin}},
  date = {1998-04-01},
  journaltitle = {Computer Networks and ISDN Systems},
  volume = {30},
  pages = {107--117},
  publisher = {{Elsevier}},
  issn = {0169-7552},
  doi = {10.1016/S0169-7552(98)00110-X},
  url = {http://www.sciencedirect.com/science/article/pii/S016975529800110X},
  urldate = {2020-08-19},
  abstract = {In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is de…},
  file = {/home/ryan/Zotero/storage/T6GP3JBH/1998 - The anatomy of a large-scale hypertextual Web sear.pdf},
  langid = {english},
  number = {1-7}
}

@inproceedings{loizouUsingWikipediaAlleviate2010a,
  title = {Using {{Wikipedia}} to Alleviate Data Sparsity Issues in {{Recommender Systems}}},
  booktitle = {2010 {{Fifth International Workshop Semantic Media Adaptation}} and {{Personalization}}},
  author = {Loizou, Antonis and Dasmahapatra, Srinandan},
  date = {2010-12},
  pages = {104--111},
  publisher = {{IEEE}},
  location = {{Limassol, Cyprus}},
  doi = {10.1109/SMAP.2010.5706870},
  url = {http://ieeexplore.ieee.org/document/5706870/},
  urldate = {2020-08-17},
  eventtitle = {2010 5th {{International Workshop}} on {{Semantic Media Adaptation}} and {{Personalization}} ({{SMAP}})},
  file = {/home/ryan/Zotero/storage/AEQWVR4N/Loizou and Dasmahapatra - 2010 - Using Wikipedia to alleviate data sparsity issues .pdf;/home/ryan/Zotero/storage/JNCTAXMR/Using Wikipedia to alleviate data sparsity issues in Recommender Systems - IEEE Conference Publication (2020-08-17 8_00_17 PM).html},
  isbn = {978-1-4244-8603-8},
  note = {For Recommender systems with limited access to data, Wikipedia can be used as an analogue with respect to connections to significantly improve performance.}
}

@online{Mathonline,
  title = {Mathonline},
  url = {http://mathonline.wikidot.com/},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/TZRWVR6E/mathonline.wikidot.com.html}
}

@article{mehrabianItSmallWorld2016,
  title = {It’s a {{Small World}} for {{Random Surfers}}},
  author = {Mehrabian, Abbas and Wormald, Nick},
  date = {2016-10-01},
  journaltitle = {Algorithmica},
  volume = {76},
  pages = {344--380},
  issn = {1432-0541},
  doi = {10.1007/s00453-015-0034-6},
  url = {https://doi.org/10.1007/s00453-015-0034-6},
  urldate = {2020-08-18},
  abstract = {We prove logarithmic upper bounds for the diameters of the random-surfer Webgraph model and the PageRank-based selection Webgraph model, confirming the small world phenomenon holds for them. In the special case when the generated graph is a tree, we provide close lower and upper bounds for the diameters of both models.},
  file = {/home/ryan/Zotero/storage/4JIE8SU3/Mehrabian and Wormald - 2016 - It’s a Small World for Random Surfers.pdf},
  langid = {english},
  note = {Graphs can be generated in order to model real world networks, these models can use the degree or page rank of a given vertex as a parameter to create the next vertex in generating the graph.
\par
This paper discusses upper and lower bounds for the diameter of a graph generated using random-surfer web-graph model.},
  number = {2}
}

@online{mitResearchGuidesExpert,
  title = {Research Guides \& Expert Librarians | {{MIT Libraries}}},
  author = {{MIT}},
  url = {https://libraries.mit.edu/experts/},
  urldate = {2020-08-19},
  abstract = {We have smart people who know how to find the best information. Use their guides or~contact them. See also: Class \& program guides. Topic guide Expert librarian Aeronautics \& astronautics Barbara Williams Anthropology \& archaeology Ece Turnator APIs for scholarly resources Katie Zimmerman Architectural design Kai Alexis Smith Architecture \& art Kai Alexis Smith Art […]},
  file = {/home/ryan/Zotero/storage/SE7IDK8X/experts.html},
  langid = {american}
}

@online{mizWikipediaGraphDataset2019,
  title = {Wikipedia {{Graph Dataset}}},
  author = {Miz, Volodymyr},
  date = {2019-06-05},
  url = {https://blog.miz.space/research/2019/06/05/wikipedia-graph-dataset-neo4j-mongodb-time-series-networks/},
  urldate = {2020-10-03},
  file = {/home/ryan/Zotero/storage/6S56XYD8/wikipedia-graph-dataset-neo4j-mongodb-time-series-networks.html}
}

@online{moskowitzLibraryGuidesWikipedia,
  title = {Library {{Guides}}: {{Wikipedia}}: {{Should You Use Wikipedia}}?},
  shorttitle = {Library {{Guides}}},
  author = {Moskowitz, Paula},
  url = {https://mville.libguides.com/c.php?g=370066&p=2500344},
  urldate = {2020-08-19},
  abstract = {This guide will discuss to use or to not use Wikipedia in research.},
  file = {/home/ryan/Zotero/storage/U7TBWA3U/c.html},
  langid = {english}
}

@inproceedings{nemaConsensusbasedRankingWikipedia2017a,
  title = {Consensus-Based Ranking of Wikipedia Topics},
  booktitle = {Proceedings of the {{International Conference}} on {{Web Intelligence}}},
  author = {Nema, Waleed and Tang, Yinshan},
  date = {2017-08-23},
  pages = {114--124},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3106426.3106529},
  url = {http://doi.org/10.1145/3106426.3106529},
  urldate = {2020-08-19},
  abstract = {To improve the effectiveness of users' information seeking experience in interactive web search we hypothesize how people might be influenced when making relevance judgment decisions by introducing the {$<$}u{$>$}C{$<$}/u{$>$}onsensus {$<$}u{$>$}T{$<$}/u{$>$}heory {$<$}u{$>\&<$}/u{$>$} Relevance Judgment {$<$}u{$>$}M{$<$}/u{$>$}odel (CT\&M). This is combined with a practical path to assess the extent of difference between suggestions of current search engines versus user expectations. A user-centered, evidence-based, phenomenology approach is used to improve on Google PageRank (GPR) in two ways. The first by biasing GPR's equal navigation probability assumption using (f)actual usage stats as implicit user consensus which leads to the StatsRank (SR) algorithm. Secondly, we aggregate users' explicit ranking to derive Consensus Rank (CR) which is shown to predict individual user ranking significantly better than GPR and meta-search of modern search engines Google and Yahoo/Bing real-time. CT\&M contextualizes CR, SR, and a live open online web experiment, called {$<$}u{$>$}The Ranking Game{$<$}/u{$>$}, which is based on the August-2016 English Wikipedia corpus (12.7 million pages) and Page View Statistics for May to July 2016. Limiting this work to Wikipedia makes GPR topic-based since any Wikipedia page is focused on one topic. TREC's pooling is used to merge top 20 results from major search engines and present an alphabetized list for users' explicit ranking via drag and drop. The same platform captures implicit data for future research and can be used for controlled experiments. Our contributions are: CT\&M, SR, CR, and the open online user feedback web experiment research platform.},
  file = {/home/ryan/Zotero/storage/Y9V4N3PF/Nema and Tang - 2017 - Consensus-based ranking of wikipedia topics.pdf},
  isbn = {978-1-4503-4951-2},
  keywords = {consensus ranking,explicit relevance feedback,google pagerank,implicit feedback,information retrieval,information seeking,interactive web search,wikipedia},
  series = {{{WI}} '17}
}

@inproceedings{ngStableAlgorithmsLink2001,
  title = {Stable Algorithms for Link Analysis},
  booktitle = {Proceedings of the 24th Annual International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval},
  author = {Ng, Andrew Y. and Zheng, Alice X. and Jordan, Michael I.},
  date = {2001-09-01},
  pages = {258--266},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/383952.384003},
  url = {http://doi.org/10.1145/383952.384003},
  urldate = {2020-08-19},
  abstract = {The Kleinberg HITS and the Google PageRank algorithms are eigenvector methods for identifying ``authoritative'' or ``influential'' articles, given hyperlink or citation information. That such algorithms should give reliable or consistent answers is surely a desideratum, and in\textasciitilde\textbackslash cite\{ijcaiPaper\}, we analyzed when they can be expected to give stable rankings under small perturbations to the linkage patterns. In this paper, we extend the analysis and show how it gives insight into ways of designing stable link analysis methods. This in turn motivates two new algorithms, whose performance we study empirically using citation data and web hyperlink data.},
  file = {/home/ryan/Zotero/storage/B3KE4TRH/Ng et al. - 2001 - Stable algorithms for link analysis.pdf},
  isbn = {978-1-58113-331-8},
  series = {{{SIGIR}} '01}
}

@book{nicholsonLinearAlgebraApplications2009,
  title = {Linear Algebra with Applications},
  author = {Nicholson, W. Keith},
  date = {2009},
  publisher = {{McGraw-Hill Ryerson}},
  location = {{Toronto}},
  annotation = {OCLC: 863604118},
  isbn = {978-0-07-098510-0},
  langid = {english}
}

@online{OverviewZettelkastenMethod,
  title = {Overview • {{Zettelkasten Method}}},
  url = {https://zettelkasten.de/posts/overview/},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/PCQJBUHH/overview.html}
}

@inproceedings{parkMiningWebMultiresolution2007,
  title = {Mining Web Multi-Resolution Community-Based Popularity for Information Retrieval},
  booktitle = {Proceedings of the Sixteenth {{ACM}} Conference on {{Conference}} on Information and Knowledge Management  - {{CIKM}} '07},
  author = {Park, Laurence A. F. and Ramamohanarao, Kotagiri},
  date = {2007},
  pages = {545},
  publisher = {{ACM Press}},
  location = {{Lisbon, Portugal}},
  doi = {10.1145/1321440.1321517},
  url = {http://portal.acm.org/citation.cfm?doid=1321440.1321517},
  urldate = {2020-08-21},
  eventtitle = {The Sixteenth {{ACM}} Conference},
  file = {/home/ryan/Zotero/storage/GG74HGIH/Mining web multi-resolution community-based popula.pdf},
  isbn = {978-1-59593-803-9},
  langid = {english}
}

@online{parkPowerWalkProceedings2013,
  title = {Power Walk | {{Proceedings}} of the 18th {{Australasian Document Computing Symposium}}},
  author = {Park, laurence and Simeon Simoff},
  date = {2013-12-05},
  url = {https://dl-acm-org.ezproxy.uws.edu.au/doi/10.1145/2537734.2537749},
  urldate = {2020-08-01},
  file = {/home/ryan/Zotero/storage/3YRMUVP9/parkPowerWalkProceedings2013.pdf;/home/ryan/Zotero/storage/FH5YZ2YM/2537734.html}
}

@inproceedings{parkPowerWalkRevisiting2013,
  title = {Power Walk: Revisiting the Random Surfer},
  shorttitle = {Power Walk},
  booktitle = {Proceedings of the 18th {{Australasian Document Computing Symposium}}},
  author = {Park, Laurence A. F. and Simoff, Simeon},
  date = {2013-12-05},
  pages = {50--57},
  publisher = {{Association for Computing Machinery}},
  location = {{Brisbane, Queensland, Australia}},
  doi = {10.1145/2537734.2537749},
  url = {http://doi.org/10.1145/2537734.2537749},
  urldate = {2020-07-31},
  abstract = {Measurement of graph centrality provides us with an indication of the importance or popularity of each vertex in a graph. When dealing with graphs that are not centrally controlled (such as the Web, social networks and academic citation graphs), centrality measure must 1) correlate with vertex importance/popularity, 2) scale well in terms of computation, and 3) be difficult to manipulate by individuals. The Random Surfer probability transition model, combined with Eigenvalue Centrality produced PageRank, which has shown to satisfy the required properties. Existing centrality measures (including PageRank) make the assumption that all directed edges are positive, implying an endorsement. Recent work on sentiment analysis has shown that this assumption is not valid. In this article, we introduce a new method of transitioning a graph, called Power Walk, that can successfully compute centrality scores for graphs with real weighted edges. We show that it satisfies the desired properties, and that its computation time and centrality ranking is similar to when using the Random Surfer model for non-negative matrices. Finally, stability and convergence analysis shows us that both stability and convergence when using the power method, are dependent on the Power Walk parameter β.},
  isbn = {978-1-4503-2524-0},
  keywords = {graph centrality,PageRank,random surfer,sentiment},
  series = {{{ADCS}} '13}
}

@article{pringleWhatTallPoppy1998,
  title = {What Is a Tall Poppy among {{Web}} Pages?},
  author = {Pringle, Glen and Allison, Lloyd and Dowe, David L.},
  date = {1998-04},
  journaltitle = {Computer Networks and ISDN Systems},
  volume = {30},
  pages = {369--377},
  issn = {01697552},
  doi = {10.1016/S0169-7552(98)00061-0},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0169755298000610},
  urldate = {2020-08-21},
  file = {/home/ryan/Zotero/storage/WXCTDRFZ/1998 - What is a tall poppy among Web pages.pdf},
  langid = {english},
  number = {1-7}
}

@online{ScienceTracerBullets,
  title = {Science {{Tracer Bullets}} ({{Science Reference Services}}, {{Science}}, {{Technology}}, and {{Business Division}}, {{Library}} of {{Congress}})},
  url = {https://www.loc.gov/rr/scitech/tracer-bullets/},
  urldate = {2020-08-19},
  abstract = {The Library of Congress SCIENCE TRACER BULLET SERIES contains research guides that help you locate information on science and technology subjects. With brief introductions to the topics, lists of resources and strategies for finding more, they help you to stay"on target." International Standard Serial Number (ISSN) 0090-5232. The series ceased in 2013. The content in these research guides is no longer being updated and links may not function; however, the resources listed in these guides may be useful as background documents to supplement current information or to provide a historical perspective on a topic. Research Finding Aids from the Library of Congress, Science Reference Services.},
  file = {/home/ryan/Zotero/storage/62W5HN9W/tracer-bullets.html},
  langid = {english},
  type = {webpage}
}

@online{springerSpringerLink,
  title = {Springer {{Link}}},
  author = {{Springer}},
  url = {http://https://link-springer-com},
  langid = {english},
  type = {Database}
}

@article{tangTwohopWalksIndicate2019,
  title = {Two-Hop Walks Indicate {{PageRank}} Order},
  author = {Tang, Ying},
  date = {2019-11-01},
  journaltitle = {Pattern Recognition},
  volume = {95},
  pages = {201--210},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2019.06.010},
  url = {http://www.sciencedirect.com/science/article/pii/S0031320319302419},
  urldate = {2020-08-19},
  abstract = {This paper shows that pairwise PageRank orders emerge from two-hop walks. The main tool used here refers to a specially designed sign-mirror function and a parameter curve, whose low-order derivative information implies pairwise PageRank orders with high probability. We study the pairwise correct rate by placing the Google matrix G in a probabilistic framework, where G may be equipped with different random ensembles for model-generated or real-world networks with sparse, small-world, scale-free features, the proof of which is mixed by mathematical and numerical evidence. We believe that the underlying spectral distribution of aforementioned networks is responsible for the high pairwise correct rate. Moreover, the perspective of this paper naturally leads to an O(1) algorithm for any single pairwise PageRank comparison if assuming both A=G−In, where In denotes the identity matrix of order n, and A2 are ready on hand (e.g., constructed offline in an incremental manner), based on which it is easy to extract the top k list in O(kn), thus making it possible for PageRank algorithm to deal with super large-scale datasets in real time.},
  file = {/home/ryan/Zotero/storage/R6NEA8SS/Tang - 2019 - Two-hop walks indicate PageRank order.pdf},
  keywords = {PageRank,Spectral ranking,Two-Hop},
  langid = {english},
  note = {Don't know what this one is about}
}

@article{tanNewExtrapolationMethod2017a,
  title = {A New Extrapolation Method for {{PageRank}} Computations},
  author = {Tan, Xueyuan},
  date = {2017-03-15},
  journaltitle = {Journal of Computational and Applied Mathematics},
  volume = {313},
  pages = {383--392},
  issn = {0377-0427},
  doi = {10.1016/j.cam.2016.08.034},
  url = {http://www.sciencedirect.com/science/article/pii/S0377042716304034},
  urldate = {2020-08-19},
  abstract = {The PageRank algorithm is widely considered these years because of its great significance in search engine technology and other scientific domains. Though the power method is the initial measure to settle the PageRank problem, it gives poor convergence when the damping factor is sufficiently close to 1. This difficulty encourages researchers to present improved iterative methods for accelerating PageRank computations. In this paper, a cheap and practical extrapolation approach which is determined by the trace of the Google matrix is proposed, and it is more attractive when combined with the well-known Arnoldi-type algorithm. Convergence analysis of our algorithms is given. Numerical examples illustrate the efficiency of these accelerated schemes.},
  file = {/home/ryan/Zotero/storage/RDHABQZD/Tan - 2017 - A new extrapolation method for PageRank computatio.pdf},
  keywords = {Arnoldi-type algorithm,Extrapolation method,PageRank,Power method,Trace},
  langid = {english},
  note = {This is exactly what laurence was saying and also what Bryan and Leise said.}
}

@book{teamSparseMatrixOperations,
  title = {6 {{Sparse Matrix Operations}} | {{Stan Functions Reference}}},
  author = {Team, Stan Development},
  url = {https://mc-stan.org/docs/2_22/functions-reference/sparse-matrices.html},
  urldate = {2020-08-07},
  abstract = {Reference for the functions defined in the Stan math library and available in the Stan programming language.},
  file = {/home/ryan/Zotero/storage/J7V6QUKX/sparse-matrices.html}
}

@online{Top100Wiki,
  title = {Top 100 {{Wiki Pages}} on {{Brilliant}} | {{Brilliant Math}} \& {{Science Wiki}}},
  url = {https://brilliant.org/wiki/best/},
  urldate = {2020-08-19},
  abstract = {On Brilliant, you can explore math, science, and engineering at any level. Whether you\&\#39;re looking to read about basic equations or quantum computing, we have wikis here for you! Vieta\&\#39;s Formula Induction Componendo and Dividendo Arithmetic Mean - Geometric Mean Inequality Cauchy-Schwarz Inequality Newton\&\#39;s Identities Eigenvalues and Eigenvectors Group Theory Introduction Equilateral Triangles Circumcenter Alternate Segment Theorem Bearing Problems Euler Line Möbius Strips Knots Guarding A Museum Even and Odd Numbers Divisiblity Rules Cryptogram Benford\&\#39;s …},
  file = {/home/ryan/Zotero/storage/ECEI82CQ/best.html},
  langid = {american}
}

@article{vilenoPaperElectronicEvolution2007,
  title = {From Paper to Electronic, the Evolution of Pathfinders: A Review of the Literature},
  shorttitle = {From Paper to Electronic, the Evolution of Pathfinders},
  author = {Vileno, Luigina},
  date = {2007-01-01},
  journaltitle = {Reference Services Review},
  volume = {35},
  pages = {434--451},
  publisher = {{Emerald Group Publishing Limited}},
  issn = {0090-7324},
  doi = {10.1108/00907320710774300},
  url = {https://doi.org/10.1108/00907320710774300},
  urldate = {2020-08-19},
  abstract = {Purpose – The purpose of this paper is to provide a review of the literature on pathfinders, from the 1970s to the present. Design/methodology/approach – The paper reviews a range of publications which describe the methodology of pathfinders, provide practical advice and information, present research results, to aid librarians and library administrators in how to best manage the production and marketing of pathfinders. Findings – It was found that not much has been written on pathfinders. A few articles on traditional pathfinders were published between 1972 and 1995. In 1996, the electronic format took over. Most of the articles are of a practical nature although some describe empirical research. One void in the literature that has been found is librarians' lack of knowledge of users' needs and preferences. This results in much time and effort being dedicated to the production of pathfinders but without any consideration of users, thus discouraging them from using the available resources. Practical implications – This paper will be a useful source of information for librarians. It provides an overview of guidelines and best practices currently reported in the literature as well as the latest technical and educational trends. Originality/value – Such an extensive review of the literature on pathfinders has not been done before. It provides practical information for librarians wanting to embark on the production of pathfinders. It also identifies possible areas of future study.},
  file = {/home/ryan/Zotero/storage/FWYGVLWV/Vileno - 2007 - From paper to electronic, the evolution of pathfin.pdf;/home/ryan/Zotero/storage/2JZHWIVJ/html.html},
  keywords = {Internet,Libraries,Reference services},
  number = {3}
}

@online{WaybackMachine2002,
  title = {Wayback {{Machine}}},
  date = {2002-05-06},
  url = {https://web.archive.org/web/20020506051802/http://www-diglib.stanford.edu/cgi-bin/WP/get/SIDL-WP-1997-0072?1},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/3WQWKZ5W/SIDL-WP-1997-0072.html}
}

@inproceedings{westCompletingWikipediaHyperlink2009,
  title = {Completing Wikipedia's Hyperlink Structure through Dimensionality Reduction},
  booktitle = {Proceeding of the 18th {{ACM}} Conference on {{Information}} and Knowledge Management - {{CIKM}} '09},
  author = {West, Robert and Precup, Doina and Pineau, Joelle},
  date = {2009},
  pages = {1097},
  publisher = {{ACM Press}},
  location = {{Hong Kong, China}},
  doi = {10.1145/1645953.1646093},
  url = {http://portal.acm.org/citation.cfm?doid=1645953.1646093},
  urldate = {2020-08-18},
  eventtitle = {Proceeding of the 18th {{ACM}} Conference},
  file = {/home/ryan/Zotero/storage/8JQAFJA6/West et al. - 2009 - Completing wikipedia's hyperlink structure through.pdf},
  isbn = {978-1-60558-512-3},
  langid = {english}
}

@online{WestlawAU,
  title = {Westlaw {{AU}}},
  url = {https://www-westlaw-com-au.ezproxy.uws.edu.au/maf/wlau/api/tocectory?ndd=1&sttype=stdtemplate&stnew=true&tds=AUNZ_TOC&ao=o.AUNZ_TOC||anzbycontenttype&stid=std-anz&expanded=2},
  urldate = {2020-08-18},
  file = {/home/ryan/Zotero/storage/RM2322NQ/tocectory.html}
}

@inreference{WikipediaSizeWikipedia2020,
  title = {Wikipedia:{{Size}} of {{Wikipedia}}},
  shorttitle = {Wikipedia},
  booktitle = {Wikipedia},
  date = {2020-08-01T03:23:08Z},
  url = {https://en.wikipedia.org/w/index.php?title=Wikipedia:Size_of_Wikipedia&oldid=970572970},
  urldate = {2020-08-20},
  abstract = {The size of the English Wikipedia can be measured in terms of the number of articles, number of words, and the size of the database, among other ways. As of 20 August 2020, there are 6,144,070 articles in the English Wikipedia containing over 3.6 billion words. Wikipedia continues to grow, and the number of articles in Wikipedia is increasing by over 17,000 a month. The number of articles added to Wikipedia every month reached its maximum in 2006, at over 50,000 new articles a month, and has been slowly but steadily declining since then. While this might seem to show that Wikipedia's growth is slowing or stopping, it should be noted that the amount of text added to Wikipedia articles every year has been constant since 2006, at roughly 1 gigabyte of (compressed) text added per year. This implies that as time progresses, proportionally more content is added to existing articles rather than new articles, and that Wikipedia has maintained the same persistent rate of growth throughout the past decade. In other words, over time, the average article size is growing faster than the number of articles. Most of the earlier entries were extracted from Wikipedia:Milestones. Later entries are taken from observations of the new software's built-in article count features. For information on what Wikipedia's software counts as an article, see Wikipedia:What is an article\#Lists of articles and statistics. The article count of bot-generated Wikipedias such as the Cebuano-language edition of Wikipedia, as well as the Swedish-, Dutch- and the Waray-language editions, grow much faster than those that are primarily written by humans such as the English Wikipedia. Swedish Wikipedian Sverker Johansson's Lsjbot is the primary author of those four primarily bot-generated Wikipedias. However, individual articles in bot-generated Wikipedias are on average much shorter than those in primarily human-written Wikipedias. Thus, article count alone is a poor indicator of the scale and scope of all Wikipedia editions.},
  annotation = {Page Version ID: 970572970},
  file = {/home/ryan/Zotero/storage/2HRFQTZM/index.html},
  langid = {english}
}

@article{willsGooglePagerank2006,
  title = {Google’s Pagerank},
  author = {Wills, Rebecca S.},
  date = {2006-09-01},
  journaltitle = {The Mathematical Intelligencer},
  volume = {28},
  pages = {6--11},
  issn = {0343-6993},
  doi = {10.1007/BF02984696},
  url = {https://doi.org/10.1007/BF02984696},
  urldate = {2020-08-19},
  file = {/home/ryan/Zotero/storage/R6AHRKBR/Wills - 2006 - Google’s pagerank.pdf},
  langid = {english},
  number = {4}
}

@article{zengPracticalSimulationMethod2013,
  title = {A {{Practical Simulation Method}} for {{Social Networks}}},
  author = {Zeng, Rui and Sheng, Quan Z and Yao, Lina and Xu, Tianwei and Xie, Dong},
  date = {2013},
  volume = {144},
  pages = {8},
  abstract = {With the increasing popularity of social networks, it is becoming more and more crucial for the decision makers to analyze and understand the evolution of these networks in order to identify e.g., potential business opportunities. Unfortunately, understanding social networks, which are typically complex and dynamic, is not an easy task. In this paper, we propose an effective and practical approach for simulating social networks. We first develop a social network model that considers the addition and deletion of nodes and edges. We consider the nodes’ in-degree, internodes’ close degree, which indicates how close the nodes are in the social network, and the limit of the network size in the social network model. We then develop a graphbased stratified random sampling algorithm for generating an initial network. To obtain the snapshots of a social network of the past, current and the future, we further develop a close degree algorithm and a close degree of estimation algorithm. The degree distribution of our model follows a power-law distribution with a “fat-tail”. Experimental results using real-life social networks show the effectiveness of our proposed simulation method.},
  file = {/home/ryan/Zotero/storage/CYZFLHU9/Zeng et al. - 2013 - A Practical Simulation Method for Social Networks.pdf},
  langid = {english}
}

@article{zhangImpactWebpageContent2005,
  title = {The Impact of Webpage Content Characteristics on Webpage Visibility in Search Engine Results ({{Part I}})},
  author = {Zhang, Jin and Dimitroff, Alexandra},
  date = {2005-05-01},
  journaltitle = {Information Processing \& Management},
  volume = {41},
  pages = {665--690},
  issn = {0306-4573},
  doi = {10.1016/j.ipm.2003.12.001},
  url = {http://www.sciencedirect.com/science/article/pii/S0306457303001122},
  urldate = {2020-08-19},
  abstract = {Content characteristics of a webpage include factors such as keyword position in a webpage, keyword duplication, layout, and their combination. These factors may impact webpage visibility in a search engine. Four hypotheses are presented relating to the impact of selected content characteristics on webpage visibility in search engine results lists. Webpage visibility can be improved by increasing the frequency of keywords in the title, in the full-text and in both the title and full-text.},
  file = {/home/ryan/Zotero/storage/DPW2PK6G/Zhang and Dimitroff - 2005 - The impact of webpage content characteristics on w.pdf},
  keywords = {Search engine optimization,Webpage placement,Webpage visibility},
  langid = {english},
  number = {3},
  series = {Cross-{{Language Information Retrieval}}}
}

@inproceedings{zhangMakingEigenvectorBasedReputation2004,
  title = {Making {{Eigenvector}}-{{Based Reputation Systems Robust}} to {{Collusion}}},
  booktitle = {Algorithms and {{Models}} for the {{Web}}-{{Graph}}},
  author = {Zhang, Hui and Goel, Ashish and Govindan, Ramesh and Mason, Kahn and Van Roy, Benjamin},
  editor = {Leonardi, Stefano},
  date = {2004},
  pages = {92--104},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-30216-2_8},
  abstract = {Eigenvector based methods in general, and Google’s PageRank algorithm for rating web pages in particular, have become an important component of information retrieval on the Web. In this paper, we study the efficacy of, and countermeasures for, collusions designed to improve user rating in such systems.We define a metric, called the amplification factor, which captures the amount of PageRank-inflation obtained by a group due to collusions. We prove that the amplification factor can be at most 1/ε, where ε is the reset probability of the PageRank random walk. We show that colluding nodes (e.g., web-pages) can achieve this amplification and increase their rank significantly in realistic settings; further, several natural schemes to address this problem are demonstrably inadequate.We propose a relatively simple modification to PageRank which renders the algorithm insensitive to such collusion attempts. Our scheme is based on the observation that nodes which cheat do so by “stalling” the random walk in a small portion of the web graph and, hence, their PageRank must be especially sensitive to the reset probability ε. We perform exhaustive simulations on the Web graph to demonstrate that our scheme successfully prevents colluding nodes from improving their rank, yielding an algorithm that is robust to gaming.},
  file = {/home/ryan/Zotero/storage/SF2BHL3C/Zhang et al. - 2004 - Making Eigenvector-Based Reputation Systems Robust.pdf},
  isbn = {978-3-540-30216-2},
  langid = {english},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{zhangModifiedPageRankAlgorithm2018,
  title = {A Modified {{PageRank}} Algorithm for Biological Pathway Ranking},
  author = {Zhang, Qingyang},
  date = {2018},
  journaltitle = {Stat},
  volume = {7},
  pages = {e204},
  issn = {2049-1573},
  doi = {10.1002/sta4.204},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.204},
  urldate = {2020-08-19},
  abstract = {Pathways are the functional building blocks of complex diseases such as cancer. Identifying disease-associated pathways is of great importance to the development of novel therapeutics, as it provides functional insights into the pathogenesis of a disease. Existing methods for pathway ranking, however, are mostly based on an enrichment score assigned to each pathway independently, which could be biased by overlooking the interactions between pathways. In this paper, we consider a modification of Google's PageRank algorithm in order to fully incorporate the pathway dependencies into the pathway ranking. The proposed measurement is a trade-off between two important aspects, namely, the phenotype–pathway association and pathway coexpression. We propose to use a projection correlation to quantify pathway coexpression, and a generalized R2 for phenotype–pathway association. Our simulation study on real pathways shows the competitive performance of the new measure compared with enrichment-based analyses in pathway ranking.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sta4.204},
  file = {/home/ryan/Zotero/storage/6RPT9C6R/Zhang - 2018 - A modified PageRank algorithm for biological pathw.pdf},
  keywords = {Google's PageRank algorithm,multinomial logit model,pathway coexpression,pathway ranking,projection correlation},
  langid = {english},
  note = {e204 sta4.204
\par
The page rank method can be used for modelling gene expression.},
  number = {1}
}

@article{zhaoOptimizingNodeDiscovery2019,
  title = {Optimizing Node Discovery on Networks: {{Problem}} Definitions, Fast Algorithms, and Observations},
  shorttitle = {Optimizing Node Discovery on Networks},
  author = {Zhao, Junzhou and Wang, Pinghui and Lui, John C. S.},
  date = {2019-03-01},
  journaltitle = {Information Sciences},
  volume = {477},
  pages = {161--185},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2018.10.036},
  url = {http://www.sciencedirect.com/science/article/pii/S0020025518308557},
  urldate = {2020-08-19},
  abstract = {We study a general node discoverability optimization problem on networks, where the goal is to create a few edges to a target node so that the target node can be easily discovered by the other nodes in the network. For instance, a jobseeker may want to connect with some members in LinkedIn so that recruiters can easily find him. We first propose two definitions of node discoverability. Then, we prove that the node discoverability optimization problem is NP-hard. We show that a greedy algorithm can be used to find near-optimal solutions. To scale up the algorithm on large networks, we design three methods: (1) an exact method based on dynamic programming, which is accurate but computationally inefficient; (2) an estimation method based on the framework of random walk, which is efficient but may be inaccurate; (3) an estimation-and-refinement method, which combines the previous two methods and we show that it is both accurate and efficient. Experiments conducted on real networks demonstrate that the estimation-and-refinement method can provide a good trade-off between solution accuracy and computational efficiency, and achieve speedup of up to three orders of magnitude over the exact method.},
  file = {/home/ryan/Zotero/storage/KKINWVC2/Zhao et al. - 2019 - Optimizing node discovery on networks Problem def.pdf},
  keywords = {Greedy algorithm,MCMC simulation,Random walk,Submodular/supermodular set function},
  langid = {english}
}


